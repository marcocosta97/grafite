{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T08:31:57.764488Z",
     "start_time": "2023-05-15T08:31:56.264841Z"
    }
   },
   "outputs": [],
   "source": [
    "# This file is part of Grafite <https://github.com/marcocosta97/grafite>.\n",
    "# Copyright (C) 2023 Marco Costa.\n",
    "#\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools, os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T08:32:51.430480Z",
     "start_time": "2023-05-15T08:32:51.321734Z"
    }
   },
   "outputs": [],
   "source": [
    "width = 5.47807\n",
    "width_small = 3.50069\n",
    "max_height = 7.944\n",
    "\n",
    "rc_fonts = {\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.size\": 10,\n",
    "    \"text.usetex\": True,\n",
    "    \"text.latex.preamble\": r\"\\usepackage[tt=false,type1=true]{libertine}\\usepackage[varqu]{zi4}\\usepackage[libertine]{newtxmath}\"}\n",
    "matplotlib.rcParams.update(rc_fonts)\n",
    "\n",
    "out_folder = Path('./figures')\n",
    "if not out_folder.exists():\n",
    "    out_folder.mkdir()\n",
    "base_csv_path = Path('./results')\n",
    "if not out_folder.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"error, cannot find the results folder\")\n",
    "\n",
    "range_filters = ['Grafite', 'Bucketing', 'SNARF', 'SuRF', 'Proteus', 'Rosetta', 'REncoder', 'REncoder_SS', 'REncoder_SE']\n",
    "range_filters_style_kwargs = {'Grafite': {'marker': 'o', 'color': 'dimgray', 'zorder': 10, 'label': 'Grafite'},\n",
    "                              'SNARF': {'marker': '^', 'color': 'C1', 'label': 'SNARF'},\n",
    "                              'SuRF': {'marker': 's', 'color': 'C2', 'label': 'SuRF'},\n",
    "                              'Proteus': {'marker': 'X', 'color': 'C3', 'label': 'Proteus'},\n",
    "                              'Rosetta': {'marker': 'd', 'color': 'C4', 'label': 'Rosetta'},\n",
    "                              'REncoder': {'marker': '>', 'color': 'C5', 'label': 'REncoder'},\n",
    "                              'REncoder_SS': {'marker': 'v', 'color': 'C6', 'label': 'REncoderSS'},\n",
    "                              'REncoder_SE': {'marker': 'h', 'color': 'C8', 'label': 'REncoderSE'},\n",
    "                              'Bucketing': {'marker': '*', 'color': 'C0', 'zorder': 9, 'label': 'Bucketing'}}\n",
    "\n",
    "range_filters_cmaps = {'Grafite': {'cmap': cm.Greys}, \n",
    "                        'SNARF': {'cmap': cm.Oranges},\n",
    "                        'SuRF': {'cmap': cm.Greens},\n",
    "                        'Proteus': {'cmap': cm.Reds},\n",
    "                        'Rosetta': {'cmap': cm.Purples}}\n",
    "\n",
    "empty_markers_style = {'linestyle': ':', 'fillstyle': 'none', 'alpha': 0.6, 'markersize': 4}\n",
    "lines_style = {'markersize': 4, 'linewidth': 0.7, 'fillstyle': 'none'}\n",
    "\n",
    "\n",
    "keys_synth = ['kuniform']\n",
    "query_synth = ['qcorrelated', 'quniform']\n",
    "\n",
    "labels_name = {'kuniform': r'$\\textsc{Uniform}$', \n",
    "               'knormal': r'$\\textsc{Normal}$',\n",
    "               'qcorrelated': r'$\\textsc{Correlated}$', \n",
    "               'quniform': r'$\\textsc{Uncorrelated}$',\n",
    "               'books': r'$\\textsc{Books}$',\n",
    "               'osm': r'$\\textsc{Osm}$',\n",
    "               'fb': r'$\\textsc{Fb}$'}\n",
    "\n",
    "keys_real = ['books', 'osm', 'fb']\n",
    "query_range = [0, 5, 10]\n",
    "query_range_label = [f\"Point queries\", \"Small range\", \"Large range\", \"Mixed range\"]\n",
    "\n",
    "datasets_synth = list(itertools.product(keys_synth, query_synth))\n",
    "datasets_real = keys_real\n",
    "\n",
    "fpr_test_path = f'{base_csv_path}/fpr_test'\n",
    "def get_file(filter, range_size, dataset_name, query_name = \"\", path=fpr_test_path):\n",
    "    filter = filter.lower()\n",
    "    if dataset_name in keys_synth or query_name:\n",
    "        p = Path(f'{path}/{dataset_name}/{range_size}_{query_name}/{filter}.csv')\n",
    "    else:\n",
    "        p = Path(f'{path}/{dataset_name}/{range_size}/{filter}.csv')\n",
    "    if not p.exists:\n",
    "        raise FileNotFoundError(f'error, {p} does not exist')\n",
    "    return p\n",
    "\n",
    "title_font_size = 10\n",
    "legend_font_size = 7.5\n",
    "ylabel_font_size = 10\n",
    "xlabel_font_size = 10\n",
    "\n",
    "max_x_axis_bpk = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4-5: bpk vs fpr for heuristics and bounded range filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_dirs = sorted(os.listdir(fpr_test_path), reverse=True)\n",
    "if len(sorted_dirs) < 1:\n",
    "    raise FileNotFoundError(\n",
    "        \"error, cannot find the latest test executed\")\n",
    "\n",
    "fpr_test_path = Path(fpr_test_path + '/' + sorted_dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_real_test_path = f'{base_csv_path}/fpr_real_test'\n",
    "\n",
    "sorted_dirs = sorted(os.listdir(fpr_real_test_path), reverse=True)\n",
    "if len(sorted_dirs) < 1:\n",
    "    raise FileNotFoundError(\n",
    "        \"error, cannot find the latest test executed\")\n",
    "\n",
    "fpr_real_test_path = Path(fpr_real_test_path + '/' + sorted_dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_fpr_test(filters, workloads, name):\n",
    "    nrows = len(workloads)\n",
    "    ncols = len(query_range)\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey='row', figsize=(width * 0.8, max_height/1.4))\n",
    "\n",
    "    iterate = list(itertools.product(workloads, filters, enumerate(query_range)))\n",
    "\n",
    "    for (x, ds, r) in iterate:\n",
    "        row = workloads.index(x)\n",
    "        (idx, ran) = r\n",
    "        try:\n",
    "            if type(x) is tuple:\n",
    "                data = pd.read_csv(get_file(ds, r[1], x[0], x[1], path=fpr_test_path))\n",
    "            else:\n",
    "                data = pd.read_csv(get_file(ds, r[1], x, path=fpr_real_test_path))\n",
    "        except: continue\n",
    "        data['fpr_opt'] = data['false_positives'] / data['n_queries']\n",
    "        data.plot(\"bpk\", \"fpr_opt\", ax=axes[row][idx], **range_filters_style_kwargs[ds], **lines_style)\n",
    "\n",
    "    ticks = [1, 1e-01, 1e-02, 1e-03, 1e-04, 1e-05, 1e-06, 0]\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_yscale('symlog', linthresh=(1e-06))\n",
    "        ax.set_xlim(right=max_x_axis_bpk)\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_ylim(bottom=-0.0000003, top=1.9)\n",
    "        ax.xaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(2))\n",
    "        ax.set_xlabel('Space [bits/key]', fontsize=xlabel_font_size)\n",
    "        ax.get_legend().remove()\n",
    "        ax.autoscale_view()\n",
    "        ax.margins(0.04)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax[0].yaxis.set_minor_locator(matplotlib.ticker.LogLocator(numticks=10, subs=\"auto\"))\n",
    "        \n",
    "    for i, k in list(enumerate(workloads)):\n",
    "        if type(k) is tuple:\n",
    "            axis_title = f'{labels_name[k[1]]}'\n",
    "        else:\n",
    "            axis_title = f'{labels_name[k]}'\n",
    "        axes[i][0].set_ylabel(axis_title + \"\\nFalse Positive Rate\", fontsize=ylabel_font_size)\n",
    "        \n",
    "    for i, _ in list(enumerate(query_range)):\n",
    "        axes[0][i].set_title(query_range_label[i], fontsize=title_font_size)\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.1)\n",
    "    fig.savefig(f'{out_folder}/fpr_test_{name}_nolegend.pdf', bbox_inches='tight', pad_inches=0.01)\n",
    "    lines, labels = axes[0][1].get_legend_handles_labels()\n",
    "\n",
    "    if len(filters) > 4:\n",
    "        ncol = len(filters) // 2\n",
    "        bbox = (0.5, 1.65)\n",
    "    else:\n",
    "        ncol = len(filters)\n",
    "        bbox = (0.5, 1.5)\n",
    "        \n",
    "    axes[0][1].legend(lines, labels, loc='upper center', bbox_to_anchor=bbox,\n",
    "            fancybox=True, shadow=False, ncol=ncol, fontsize=legend_font_size)\n",
    "    fig.savefig(f'{out_folder}/fpr_test_{name}.pdf', bbox_inches='tight', pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def generate_tables(filters, workloads):\n",
    "    nrows = len(workloads)\n",
    "    workload_row = [collections.defaultdict(list) for _ in range(nrows)]\n",
    "    iterate = list(itertools.product(workloads, filters, enumerate(query_range)))\n",
    "\n",
    "    for (x, ds, r) in iterate:\n",
    "        row = workloads.index(x)\n",
    "        try:\n",
    "            if type(x) is tuple:\n",
    "                data = pd.read_csv(get_file(ds, r[1], x[0], x[1], path=fpr_test_path))\n",
    "            else:\n",
    "                data = pd.read_csv(get_file(ds, r[1], x, path=fpr_real_test_path))\n",
    "        except: continue\n",
    "        data[\"single_query_time\"] = (data[\"query_time\"] / data[\"n_queries\"]) * 10**6\n",
    "        workload_row[row][range_filters_style_kwargs[ds]['label']].append(round(data[\"single_query_time\"].mean(), 2))\n",
    "\n",
    "    mean_row = [collections.defaultdict(list) for _ in range(nrows)]\n",
    "    for i in range(nrows):\n",
    "        for key, value in workload_row[i].items():\n",
    "            mean_row[i][key].append(round(np.mean(value)))\n",
    "        default_value = mean_row[i][filters[0]][0]\n",
    "        for key, value in mean_row[i].items():\n",
    "            mean_row[i][key].append(round(value[0]/default_value, 2))\n",
    "\n",
    "    df_list = []\n",
    "    for i in range(nrows): \n",
    "        df = pd.DataFrame()\n",
    "        for key, value in mean_row[i].items():\n",
    "            col_name = 'Avg ns/query'\n",
    "            df.at[key, 'avg'] = value[0]\n",
    "            df.at[key, col_name] = str(value[0]) + ' (' + str(value[1]) + '$\\\\times$)'\n",
    "\n",
    "        # sort by 'temp' column ignoring the row of index 'Grafite'\n",
    "        df.iat[0, df.columns.get_loc('avg')] = -1\n",
    "        df = df.sort_values(by=['avg'])\n",
    "        # remove the 'temp' column\n",
    "        df = df.drop('avg', axis=1)\n",
    "        df_list.append(df)\n",
    "        \n",
    "    return df_list\n",
    "\n",
    "def print_table(df_list, filename, space_em_list):\n",
    "    filled_sections = []\n",
    "    filled_sections.append(\"\\\\begin{tabular}{rl}\")\n",
    "    for i, df in enumerate(df_list):\n",
    "        filled_sections.append(\"\\\\toprule\")\n",
    "        if i == 0:\n",
    "            filled_sections.append(\"Range filter & Avg ns/query \\\\\\\\\")\n",
    "            filled_sections.append(\"\\\\midrule\")\n",
    "        table_string = df.to_latex(index=True, header=False, escape=False)\n",
    "        filled_sections.extend(table_string.split(\"\\n\")[3:-2])    \n",
    "        filled_sections.append(\"\\\\vspace{\" + space_em_list[i] + \"}\\\\\\\\\")\n",
    "    \n",
    "    filled_sections.append(\"\\\\end{tabular}\")\n",
    "    # Join all filled sections\n",
    "    filled_template = \"\\n\".join(filled_sections)\n",
    "    \n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(filled_template)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "workloads = [('kuniform', 'qcorrelated'), ('kuniform', 'quniform'), ('books'), ('osm')]\n",
    "filters_heuristics = ['Bucketing', 'SuRF', 'Proteus', 'SNARF', 'REncoder_SS', 'REncoder_SE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_fpr_test(filters_heuristics, workloads, 'heuristics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = generate_tables(filters_heuristics, workloads)\n",
    "spaces_list = ['.7em', '.7em', '.7em', '1.4em']\n",
    "print_table(df_list, f'{out_folder}/table_heuristics.tex', spaces_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_bounded = ['Grafite', 'Rosetta', 'REncoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_fpr_test(filters_bounded, workloads, 'bounded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = generate_tables(filters_bounded, workloads)\n",
    "spaces_list = ['4em', '4.4em', '4.4em', '3em']\n",
    "print_table(df_list, f'{out_folder}/table_bounded.tex', spaces_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7: input size vs construction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_test_path = f'{base_csv_path}/constr_time_test'\n",
    "\n",
    "sorted_dirs = sorted(os.listdir(size_test_path), reverse=True)\n",
    "if len(sorted_dirs) < 1:\n",
    "    raise FileNotFoundError(\n",
    "        \"error, cannot find the latest test executed\")\n",
    "\n",
    "size_test_path = Path(size_test_path + '/' + sorted_dirs[0])\n",
    "\n",
    "keys_size = [5, 6, 7, 8]\n",
    "labels_keys_size = [f'$10^{x}$' for x in keys_size]\n",
    "\n",
    "matplotlib.rcParams['hatch.linewidth'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7: input size vs construction time\n",
    "old_range_filters = range_filters\n",
    "range_filters = ['Grafite', 'Bucketing', 'SNARF', 'SuRF', 'Proteus', 'Rosetta', 'REncoder']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(width_small * 0.78, 0.4 * width))\n",
    "\n",
    "width_bars = 0.12  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "iterate = list(itertools.product(keys_size, range_filters))\n",
    "for (r, ds) in iterate:\n",
    "    i = r - min(keys_size)\n",
    "    try:\n",
    "        data = pd.read_csv(get_file(ds, 5, f'kuniform_{r}', query_name='quniform', path=size_test_path))\n",
    "    except: continue\n",
    "    if data.empty or data[\"build_time\"].empty: continue\n",
    "\n",
    "    if \"modelling_time\" in data.columns:\n",
    "        build_time = np.mean(data['build_time'])/data['n_keys'] * 10**6\n",
    "        modelling_time = np.mean(data['modelling_time'])/data['n_keys'] * 10**6\n",
    "        ax.bar(range_filters.index(ds) * width_bars + i, build_time, width_bars, color=range_filters_style_kwargs[ds]['color'])\n",
    "        ax.bar(range_filters.index(ds) * width_bars + i, modelling_time, width_bars, label='_nolegend_', bottom=build_time, color=range_filters_style_kwargs[ds]['color'], alpha=0.1, hatch='//////')\n",
    "    else:\n",
    "        build_time = np.mean(data['build_time'])/data['n_keys'] * 10**6\n",
    "        ax.bar(range_filters.index(ds) * width_bars + i, build_time, width_bars, color=range_filters_style_kwargs[ds]['color'])\n",
    "\n",
    "ax.set_ylabel('Construction Time [ns/key]', fontsize=ylabel_font_size)\n",
    "ax.legend(range_filters, loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=False, ncol=1, fontsize=legend_font_size)\n",
    "ax.set_xticks(np.arange(len(keys_size)) + 3 * width_bars, labels_keys_size)\n",
    "ax.set_xlabel('Number of Keys', fontsize=xlabel_font_size)\n",
    "ax.yaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(100))\n",
    "leg = ax.get_legend()\n",
    "for ds in range_filters:\n",
    "    leg.legend_handles[range_filters.index(ds)].set_color(range_filters_style_kwargs[ds]['color'])\n",
    "\n",
    "\n",
    "fig.savefig(f'{out_folder}/constr_time_test.pdf', bbox_inches='tight', pad_inches=0.01)\n",
    "range_filters = old_range_filters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6: bpk vs query time (true queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test_path = f'{base_csv_path}/true_test'\n",
    "\n",
    "sorted_dirs = sorted(os.listdir(true_test_path), reverse=True)\n",
    "if len(sorted_dirs) < 1:\n",
    "    raise FileNotFoundError(\n",
    "        \"error, cannot find the latest test executed\")\n",
    "\n",
    "true_test_path = Path(true_test_path + '/' + sorted_dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6: bpk vs query time (true queries)\n",
    "\n",
    "keys_synth = ['kuniform']\n",
    "nrows = len(keys_synth)\n",
    "ncols = len(query_range)\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey='row', figsize=(width * 0.8, 0.2 * width))\n",
    "\n",
    "iterate = list(itertools.product(range_filters, enumerate(query_range)))\n",
    "\n",
    "for (ds, r) in iterate:\n",
    "    (idx, ran) = r\n",
    "    try:\n",
    "        data = pd.read_csv(get_file(ds, r[1], 'kuniform', 'qtrue', true_test_path))\n",
    "    except: continue\n",
    "    data[\"single_query_time\"] = (data[\"query_time\"] / data[\"n_queries\"]) * 10**6\n",
    "    data.plot(\"bpk\", \"single_query_time\", ax=axes[idx], **range_filters_style_kwargs[ds], **lines_style)\n",
    "\n",
    "ticks = [10**2, 10**3, 10**4, 10**5]\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlim(right=max_x_axis_bpk)\n",
    "    ax.xaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(2))\n",
    "    ax.set_xlabel('Space [bits/key]', fontsize=xlabel_font_size)\n",
    "    ax.set_yscale('log')\n",
    "    ax.get_legend().remove()\n",
    "    ax.yaxis.set_minor_locator(matplotlib.ticker.LogLocator(numticks=10, subs='auto'))\n",
    "    ax.set_yticks(ticks)\n",
    "\n",
    "for i, k in list(enumerate(keys_synth)):\n",
    "    axis_title = f'{k}'\n",
    "    axes[i].set_ylabel(\"Time [ns/query]\", fontsize=ylabel_font_size)\n",
    "    \n",
    "for i, _ in list(enumerate(query_range)):\n",
    "    axes[i].set_title(query_range_label[i], fontsize=title_font_size)\n",
    "    \n",
    "fig.subplots_adjust(wspace=0.1)\n",
    "fig.savefig(f'{out_folder}/true_queries_test_nolegend.pdf', bbox_inches='tight', pad_inches=0.01)\n",
    "box = axes[2].get_position()\n",
    "lines, labels = axes[0].get_legend_handles_labels()\n",
    "# order = [0,1,5,2,6,3,7,4,8]\n",
    "axes[2].legend(lines, labels, \n",
    "                  loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  fancybox=True, shadow=False, ncol=2, fontsize=legend_font_size, columnspacing=0.5)\n",
    "\n",
    "fig.savefig(f'{out_folder}/true_queries_test.pdf', bbox_inches='tight', pad_inches=0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3: Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_test_path = f'{base_csv_path}/corr_test'\n",
    "\n",
    "sorted_dirs = sorted(os.listdir(corr_test_path), reverse=True)\n",
    "if len(sorted_dirs) < 1:\n",
    "    raise FileNotFoundError(\n",
    "        \"error, cannot find the latest test executed\")\n",
    "\n",
    "corr_test_path = Path(corr_test_path + '/' + sorted_dirs[0])\n",
    "\n",
    "corr_degrees = range(0, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Correlation\n",
    "fig, axes = plt.subplots(2, 3, sharex=True, sharey='row', figsize=(width, 0.6 * width))\n",
    "\n",
    "range_filters_corr = ['Grafite', 'Bucketing', 'SNARF', 'SuRF', 'Proteus', 'Rosetta', 'REncoder', 'REncoder_SS', 'REncoder_SE']\n",
    "\n",
    "iterate = list(itertools.product(range_filters_corr, enumerate(query_range), corr_degrees))\n",
    "\n",
    "values = [dict() for x in range(len(query_range))]\n",
    "time_values = [dict() for x in range(len(query_range))]\n",
    "\n",
    "for ds in range_filters_corr:\n",
    "    for r in range(len(query_range)):\n",
    "        values[r][ds] = []\n",
    "        time_values[r][ds] = []\n",
    "        \n",
    "xlabels_corr = [ x/10 for x in corr_degrees ]\n",
    "\n",
    "for (ds, r, deg) in iterate:\n",
    "    (idx, ran) = r\n",
    "    try:\n",
    "        data = pd.read_csv(get_file(ds, r[1], f'kuniform_{deg}', 'qcorrelated', corr_test_path))\n",
    "        data['fpr_opt'] = data['false_positives'] / data['n_queries']  \n",
    "        time = data['query_time'][0]/data['n_queries'][0] * 10**6\n",
    "        fpr = data['fpr_opt'][0]\n",
    "    except:\n",
    "        fpr = None\n",
    "        time = None\n",
    "    values[idx][ds].append(fpr)\n",
    "    time_values[idx][ds].append(time)\n",
    "    \n",
    "for r in range(len(query_range)):\n",
    "    for key, data_list in values[r].items():\n",
    "        axes[0][r].plot(xlabels_corr, data_list, **range_filters_style_kwargs[key], **lines_style)\n",
    "            \n",
    "for r in range(len(query_range)):\n",
    "    for key, data_list in time_values[r].items():\n",
    "        axes[1][r].plot(xlabels_corr, data_list, **range_filters_style_kwargs[key], **lines_style)   \n",
    "    axes[1][r].set_ylim(10**1, 10**6)\n",
    "    axes[1][r].set_yscale('log')\n",
    "    \n",
    "axes[1][0].set_ylabel('Time [ns/query]', fontsize=ylabel_font_size)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.margins(0.04)\n",
    "    ax.set_yscale('symlog', linthresh=(1e-05))\n",
    "    ax.xaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(0.1))\n",
    "    \n",
    "for ax in axes[1].flatten():\n",
    "    ax.set_xlabel('Correlation Degree', fontsize=xlabel_font_size)\n",
    "    ax.yaxis.set_minor_locator(matplotlib.ticker.LogLocator(numticks=10, subs='auto'))\n",
    "    \n",
    "for i, _ in list(enumerate(query_range)):\n",
    "    axes[0][i].set_title(query_range_label[i], fontsize=xlabel_font_size)\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "axes[0][0].set_ylabel('False Positive Rate', fontsize=ylabel_font_size)\n",
    "axes[0][0].yaxis.set_minor_locator(matplotlib.ticker.LogLocator(numticks=10, subs='auto'))\n",
    "\n",
    "plt.savefig(f'{out_folder}/corr_test_twolines_nolegend.pdf', bbox_inches='tight', pad_inches=0.01)\n",
    "box = axes[0][2].get_position()\n",
    "lines, labels = axes[0][0].get_legend_handles_labels()\n",
    "# order = [0,4,1,5,2,6,3,4]\n",
    "order = list(range(len(range_filters_corr)))\n",
    "axes[0][2].legend([lines[idx] for idx in order],[labels[idx] for idx in order], \n",
    "                  loc='center left', bbox_to_anchor=(1, -0.05),\n",
    "                  fancybox=True, shadow=False, ncol=1, fontsize=legend_font_size)\n",
    "\n",
    "plt.savefig(f'{out_folder}/corr_test_twolines.pdf', bbox_inches='tight', pad_inches=0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Figure 1: Correlation (small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Correlation (small)\n",
    "range_filters_corr = ['Grafite', 'SNARF', 'SuRF', 'Proteus', 'Rosetta', 'REncoder']\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, figsize=(width_small * 1.2, 0.3 * width))\n",
    "query_range_small = [5]\n",
    "\n",
    "iterate = list(itertools.product(range_filters_corr, enumerate(query_range_small), corr_degrees))\n",
    "values = [dict() for x in range(len(query_range_small))]\n",
    "time_values = [dict() for x in range(len(query_range_small))]\n",
    "\n",
    "for ds in range_filters_corr:\n",
    "    for r in range(len(query_range_small)):\n",
    "        values[r][ds] = []\n",
    "        time_values[r][ds] = []\n",
    "        \n",
    "xlabels_corr = [ x/10 for x in corr_degrees ]\n",
    "\n",
    "for (ds, r, deg) in iterate:\n",
    "    (idx, ran) = r\n",
    "    try:\n",
    "        data = pd.read_csv(get_file(ds, r[1], f'kuniform_{deg}', 'qcorrelated', corr_test_path))\n",
    "        data['fpr_opt'] = data['false_positives'] / data['n_queries']\n",
    "        fpr = data['fpr'][0]\n",
    "        time = data['query_time'][0]/data['n_queries'][0] * 10**6\n",
    "    except:\n",
    "        fpr = None\n",
    "        time = None\n",
    "    values[idx][ds].append(fpr)\n",
    "    time_values[idx][ds].append(time)\n",
    "    \n",
    "for key, data_list in values[0].items():\n",
    "    axes[0].plot(xlabels_corr, data_list, **range_filters_style_kwargs[key], **lines_style)\n",
    "            \n",
    "for key, data_list in time_values[0].items():\n",
    "    axes[1].plot(xlabels_corr, data_list, **range_filters_style_kwargs[key], **lines_style)   \n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "axes[1].set_ylabel('Time [ns/query]', fontsize=ylabel_font_size)\n",
    "axes[1].set_ylim(10**2, 10**4)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Correlation Degree', fontsize=xlabel_font_size)\n",
    "    ax.xaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(0.1))\n",
    "    ax.set_xticks([0, 0.5, 1])\n",
    "\n",
    "box = axes[1].get_position()\n",
    "lines, labels = axes[0].get_legend_handles_labels()\n",
    "lines2, labels2 = axes[1].get_legend_handles_labels()\n",
    "axes[1].xaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%g'))\n",
    "axes[1].legend(lines, labels, loc='upper center', bbox_to_anchor=(-0.3, -0.35),\n",
    "          fancybox=True, shadow=False, ncol=3, columnspacing=0.5, fontsize=legend_font_size)\n",
    "axes[0].set_ylabel('False Positive Rate', fontsize=ylabel_font_size)\n",
    "axes[0].yaxis.set_minor_locator(matplotlib.ticker.LogLocator(numticks=10, subs='auto'))\n",
    "axes[0].set_yticks([1, 1e-01, 1e-02, 1e-03, 1e-04])\n",
    "fig.align_ylabels([axes[0], axes[1]])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.savefig(f'{out_folder}/corr_test_small.pdf', bbox_inches='tight', pad_inches=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25954afb5520d3c316f3fa05612fadff0c0b9e13ced806e8c7c52c3bc2c1252a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
